# InvestIQ Platform è´¡çŒ®æŒ‡å—

## ğŸ¤ æ¬¢è¿è´¡çŒ®

æ„Ÿè°¢æ‚¨å¯¹InvestIQ Platformçš„å…³æ³¨ï¼æˆ‘ä»¬æ¬¢è¿å„ç§å½¢å¼çš„è´¡çŒ®ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š

- ğŸ› é”™è¯¯æŠ¥å‘Šå’Œä¿®å¤
- âœ¨ æ–°åŠŸèƒ½å¼€å‘
- ğŸ“š æ–‡æ¡£æ”¹è¿›
- ğŸ”§ æ€§èƒ½ä¼˜åŒ–
- ğŸ§ª æµ‹è¯•ç”¨ä¾‹æ·»åŠ 

## ğŸ“‹ è´¡çŒ®æµç¨‹

### 1. å‡†å¤‡å·¥ä½œ

#### Forké¡¹ç›®
```bash
# 1. åœ¨GitHubä¸ŠForké¡¹ç›®åˆ°æ‚¨çš„è´¦æˆ·
# 2. å…‹éš†æ‚¨çš„Forkåˆ°æœ¬åœ°
git clone https://github.com/YOUR_USERNAME/investiq-platform.git
cd investiq-platform

# 3. æ·»åŠ ä¸Šæ¸¸ä»“åº“
git remote add upstream https://github.com/firetoss/investiq-platform.git
```

#### è®¾ç½®å¼€å‘ç¯å¢ƒ
```bash
# å®‰è£…uvåŒ…ç®¡ç†å™¨
curl -LsSf https://astral.sh/uv/install.sh | sh

# å®‰è£…é¡¹ç›®ä¾èµ–
uv sync --all-extras

# å®‰è£…å¼€å‘å·¥å…·
uv run pre-commit install

# éªŒè¯ç¯å¢ƒ
uv run python --version
uv run pytest --version
```

### 2. å¼€å‘æµç¨‹

#### åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
```bash
# åŒæ­¥æœ€æ–°ä»£ç 
git fetch upstream
git checkout main
git merge upstream/main

# åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
git checkout -b feature/your-feature-name
# æˆ–
git checkout -b fix/your-bug-fix
```

#### å¼€å‘å’Œæµ‹è¯•
```bash
# å¯åŠ¨å¼€å‘ç¯å¢ƒ
docker-compose -f docker-compose.jetson.yml up -d postgres redis minio

# å¯åŠ¨ä¸»åº”ç”¨ (å¼€å‘æ¨¡å¼)
uv run uvicorn backend.app.main:app --reload --host 0.0.0.0 --port 8000

# è¿è¡Œæµ‹è¯•
uv run pytest backend/tests/ -v

# ä»£ç æ ¼å¼åŒ–
uv run black backend/
uv run isort backend/

# ç±»å‹æ£€æŸ¥
uv run mypy backend/
```

### 3. æäº¤ä»£ç 

#### æäº¤è§„èŒƒ
ä½¿ç”¨[Conventional Commits](https://www.conventionalcommits.org/)æ ¼å¼ï¼š

```bash
# åŠŸèƒ½å¼€å‘
git commit -m "feat(ai): add RoBERTa sentiment analysis model"

# é”™è¯¯ä¿®å¤
git commit -m "fix(docker): resolve DLA core allocation issue"

# æ–‡æ¡£æ›´æ–°
git commit -m "docs(readme): update deployment instructions"

# æ€§èƒ½ä¼˜åŒ–
git commit -m "perf(jetson): optimize GPU memory usage"

# ä»£ç é‡æ„
git commit -m "refactor(services): migrate to microservices architecture"
```

#### æäº¤ç±»å‹
- `feat`: æ–°åŠŸèƒ½
- `fix`: é”™è¯¯ä¿®å¤
- `docs`: æ–‡æ¡£æ›´æ–°
- `style`: ä»£ç æ ¼å¼åŒ–
- `refactor`: ä»£ç é‡æ„
- `perf`: æ€§èƒ½ä¼˜åŒ–
- `test`: æµ‹è¯•ç›¸å…³
- `chore`: æ„å»ºè¿‡ç¨‹æˆ–è¾…åŠ©å·¥å…·çš„å˜åŠ¨

### 4. åˆ›å»ºPull Request

#### PRå‡†å¤‡
```bash
# ç¡®ä¿ä»£ç è´¨é‡
uv run pre-commit run --all-files

# è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
uv run pytest backend/tests/ --cov=backend --cov-report=html

# æ¨é€åˆ†æ”¯
git push origin feature/your-feature-name
```

#### PRæ¨¡æ¿
åœ¨GitHubä¸Šåˆ›å»ºPRæ—¶ï¼Œè¯·åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š

```markdown
## ğŸ“ å˜æ›´æè¿°
ç®€è¦æè¿°æ‚¨çš„æ›´æ”¹å†…å®¹å’ŒåŸå› ã€‚

## ğŸ”§ å˜æ›´ç±»å‹
- [ ] é”™è¯¯ä¿®å¤
- [ ] æ–°åŠŸèƒ½
- [ ] æ€§èƒ½ä¼˜åŒ–
- [ ] æ–‡æ¡£æ›´æ–°
- [ ] ä»£ç é‡æ„

## ğŸ§ª æµ‹è¯•
- [ ] å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] é›†æˆæµ‹è¯•é€šè¿‡
- [ ] åœ¨Jetsonè®¾å¤‡ä¸Šæµ‹è¯•é€šè¿‡
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•é€šè¿‡

## ğŸ“‹ æ£€æŸ¥æ¸…å•
- [ ] ä»£ç éµå¾ªé¡¹ç›®è§„èŒƒ
- [ ] æ·»åŠ äº†å¿…è¦çš„æµ‹è¯•
- [ ] æ›´æ–°äº†ç›¸å…³æ–‡æ¡£
- [ ] é€šè¿‡äº†æ‰€æœ‰CIæ£€æŸ¥

## ğŸ“¸ æˆªå›¾/æ¼”ç¤º
å¦‚æœé€‚ç”¨ï¼Œè¯·æ·»åŠ æˆªå›¾æˆ–æ¼”ç¤ºè§†é¢‘ã€‚

## ğŸ”— ç›¸å…³Issue
Closes #(issue number)
```

## ğŸ“š å¼€å‘æŒ‡å—

### ä»£ç è§„èŒƒ

#### Pythonä»£ç è§„èŒƒ
- **æ ¼å¼åŒ–**: ä½¿ç”¨black (line-length=88)
- **å¯¼å…¥æ’åº**: ä½¿ç”¨isort (profile=black)
- **ç±»å‹æ³¨è§£**: æ‰€æœ‰å…¬å…±å‡½æ•°å¿…é¡»æœ‰ç±»å‹æ³¨è§£
- **æ–‡æ¡£å­—ç¬¦ä¸²**: ä½¿ç”¨Googleé£æ ¼çš„docstring
- **å‘½åè§„èŒƒ**: 
  - å˜é‡å’Œå‡½æ•°: snake_case
  - ç±»å: PascalCase
  - å¸¸é‡: UPPER_CASE

#### ç¤ºä¾‹ä»£ç 
```python
from typing import List, Dict, Optional
import logging

logger = logging.getLogger(__name__)


class AIServiceClient:
    """AIæœåŠ¡å®¢æˆ·ç«¯
    
    æä¾›ä¸AIæœåŠ¡çš„HTTPé€šä¿¡æ¥å£ã€‚
    
    Args:
        base_url: æœåŠ¡åŸºç¡€URL
        timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´
    """
    
    def __init__(self, base_url: str, timeout: float = 30.0) -> None:
        self.base_url = base_url
        self.timeout = timeout
    
    async def predict(
        self, 
        data: List[float], 
        model_name: Optional[str] = None
    ) -> Dict[str, Any]:
        """æ‰§è¡Œé¢„æµ‹
        
        Args:
            data: è¾“å…¥æ•°æ®
            model_name: æ¨¡å‹åç§°
            
        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
            
        Raises:
            ValueError: å½“è¾“å…¥æ•°æ®æ— æ•ˆæ—¶
            httpx.HTTPError: å½“HTTPè¯·æ±‚å¤±è´¥æ—¶
        """
        if not data:
            raise ValueError("è¾“å…¥æ•°æ®ä¸èƒ½ä¸ºç©º")
        
        # å®ç°é€»è¾‘...
        return {"predictions": []}
```

### æµ‹è¯•è§„èŒƒ

#### å•å…ƒæµ‹è¯•
```python
import pytest
from unittest.mock import AsyncMock, patch

from backend.app.services.ai_clients import LLMServiceClient


class TestLLMServiceClient:
    """LLMæœåŠ¡å®¢æˆ·ç«¯æµ‹è¯•"""
    
    @pytest.fixture
    def client(self):
        return LLMServiceClient("http://test-service:8001")
    
    @pytest.mark.asyncio
    async def test_inference_success(self, client):
        """æµ‹è¯•æ¨ç†æˆåŠŸåœºæ™¯"""
        with patch('httpx.AsyncClient.post') as mock_post:
            mock_post.return_value.json.return_value = {
                "choices": [{"text": "æµ‹è¯•å›ç­”"}]
            }
            
            result = await client.inference("æµ‹è¯•æç¤º")
            
            assert result["text"] == "æµ‹è¯•å›ç­”"
            mock_post.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_inference_failure(self, client):
        """æµ‹è¯•æ¨ç†å¤±è´¥åœºæ™¯"""
        with patch('httpx.AsyncClient.post') as mock_post:
            mock_post.side_effect = Exception("ç½‘ç»œé”™è¯¯")
            
            result = await client.inference("æµ‹è¯•æç¤º")
            
            assert "error" in result
```

#### é›†æˆæµ‹è¯•
```python
import pytest
import httpx

@pytest.mark.integration
class TestAPIIntegration:
    """APIé›†æˆæµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_full_analysis_pipeline(self):
        """æµ‹è¯•å®Œæ•´åˆ†ææµæ°´çº¿"""
        async with httpx.AsyncClient() as client:
            # æµ‹è¯•æ”¿ç­–åˆ†æ
            response = await client.post(
                "http://localhost:8000/api/v1/analysis/policy",
                json={"policy_text": "æµ‹è¯•æ”¿ç­–å†…å®¹"}
            )
            assert response.status_code == 200
            
            # æµ‹è¯•æƒ…æ„Ÿåˆ†æ
            response = await client.post(
                "http://localhost:8000/api/v1/ai/sentiment/analyze",
                json={"texts": ["æµ‹è¯•æ–°é—»å†…å®¹"]}
            )
            assert response.status_code == 200
```

### æ€§èƒ½æµ‹è¯•

#### åŸºå‡†æµ‹è¯•
```python
import time
import asyncio
from typing import List

async def benchmark_llm_inference(prompts: List[str]) -> Dict[str, float]:
    """LLMæ¨ç†æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    start_time = time.time()
    
    tasks = []
    for prompt in prompts:
        task = ai_clients.llm_client.inference(prompt)
        tasks.append(task)
    
    results = await asyncio.gather(*tasks)
    
    total_time = time.time() - start_time
    throughput = len(prompts) / total_time
    
    return {
        "total_time": total_time,
        "throughput": throughput,
        "avg_latency": total_time / len(prompts)
    }
```

## ğŸ”§ å¼€å‘å·¥å…·

### æ¨èIDEé…ç½®

#### VSCodeé…ç½® (.vscode/settings.json)
```json
{
    "python.defaultInterpreterPath": "./.venv/bin/python",
    "python.linting.enabled": true,
    "python.linting.pylintEnabled": false,
    "python.linting.flake8Enabled": true,
    "python.formatting.provider": "black",
    "python.sortImports.args": ["--profile", "black"],
    "editor.formatOnSave": true,
    "editor.codeActionsOnSave": {
        "source.organizeImports": true
    }
}
```

### è°ƒè¯•é…ç½®

#### æœ¬åœ°è°ƒè¯•
```bash
# å¯åŠ¨è°ƒè¯•æ¨¡å¼
export FASTAPI_ENV=development
export LOG_LEVEL=DEBUG

# å¯åŠ¨ä¸»åº”ç”¨
uv run uvicorn backend.app.main:app --reload --host 0.0.0.0 --port 8000

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯å¯åŠ¨AIæœåŠ¡ (ç”¨äºè°ƒè¯•)
cd backend/app/services
python sentiment_server.py  # ç«¯å£8002
python timeseries_server.py  # ç«¯å£8003
python cpu_timeseries_server.py  # ç«¯å£8004
```

#### å®¹å™¨è°ƒè¯•
```bash
# è¿›å…¥å®¹å™¨è°ƒè¯•
docker-compose -f docker-compose.jetson.yml exec investiq-app bash

# æŸ¥çœ‹å®¹å™¨å†…éƒ¨çŠ¶æ€
docker-compose -f docker-compose.jetson.yml exec llm-service nvidia-smi
docker-compose -f docker-compose.jetson.yml exec sentiment-service python -c "import torch; print(torch.cuda.is_available())"
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–æŒ‡å—

### AIæ¨¡å‹ä¼˜åŒ–

#### 1. æ¨¡å‹é‡åŒ–
```python
# ç¤ºä¾‹: è‡ªå®šä¹‰æ¨¡å‹é‡åŒ–
from transformers import AutoModel
import torch

model = AutoModel.from_pretrained("model-name")
quantized_model = torch.quantization.quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8
)
```

#### 2. æ‰¹å¤„ç†ä¼˜åŒ–
```python
# ä¼˜åŒ–æ‰¹å¤„ç†å¤§å°
OPTIMAL_BATCH_SIZES = {
    "sentiment_analysis": 32,  # DLA0ä¼˜åŒ–
    "timeseries_prediction": 16,  # DLA1ä¼˜åŒ–
    "llm_inference": 1,  # GPUä¼˜åŒ–
}
```

### Jetsonç¡¬ä»¶ä¼˜åŒ–

#### 1. DLAä¼˜åŒ–
```python
# DLAæ¨¡å‹éƒ¨ç½²ç¤ºä¾‹
import torch

# è®¾ç½®DLAè®¾å¤‡
device = torch.device("cuda:0")  # DLAé€šè¿‡CUDAæ¥å£è®¿é—®
model = model.to(device)
model.half()  # ä½¿ç”¨FP16ç²¾åº¦

# å¯ç”¨DLAä¼˜åŒ–
torch.backends.cudnn.benchmark = True
```

#### 2. å†…å­˜ä¼˜åŒ–
```python
# å†…å­˜ç®¡ç†æœ€ä½³å®è·µ
import gc
import torch

def optimize_memory():
    """ä¼˜åŒ–GPUå†…å­˜ä½¿ç”¨"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
```

## ğŸ› é—®é¢˜æŠ¥å‘Š

### BugæŠ¥å‘Šæ¨¡æ¿
```markdown
**æè¿°é—®é¢˜**
ç®€è¦æè¿°é‡åˆ°çš„é—®é¢˜ã€‚

**å¤ç°æ­¥éª¤**
1. æ‰§è¡Œ '...'
2. ç‚¹å‡» '....'
3. æ»šåŠ¨åˆ° '....'
4. çœ‹åˆ°é”™è¯¯

**æœŸæœ›è¡Œä¸º**
æè¿°æ‚¨æœŸæœ›å‘ç”Ÿçš„æƒ…å†µã€‚

**å®é™…è¡Œä¸º**
æè¿°å®é™…å‘ç”Ÿçš„æƒ…å†µã€‚

**ç¯å¢ƒä¿¡æ¯**
- è®¾å¤‡: Jetson Orin AGX
- JetPackç‰ˆæœ¬: 36.4.4
- Dockerç‰ˆæœ¬: 24.0.x
- é¡¹ç›®ç‰ˆæœ¬: v1.0.0

**æ—¥å¿—ä¿¡æ¯**
```
ç²˜è´´ç›¸å…³çš„é”™è¯¯æ—¥å¿—
```

**æˆªå›¾**
å¦‚æœé€‚ç”¨ï¼Œæ·»åŠ æˆªå›¾æ¥å¸®åŠ©è§£é‡Šé—®é¢˜ã€‚
```

### åŠŸèƒ½è¯·æ±‚æ¨¡æ¿
```markdown
**åŠŸèƒ½æè¿°**
ç®€è¦æè¿°æ‚¨å¸Œæœ›æ·»åŠ çš„åŠŸèƒ½ã€‚

**ä½¿ç”¨åœºæ™¯**
æè¿°è¿™ä¸ªåŠŸèƒ½çš„ä½¿ç”¨åœºæ™¯å’Œä»·å€¼ã€‚

**å»ºè®®å®ç°**
å¦‚æœæœ‰å…·ä½“çš„å®ç°å»ºè®®ï¼Œè¯·æè¿°ã€‚

**æ›¿ä»£æ–¹æ¡ˆ**
æè¿°æ‚¨è€ƒè™‘è¿‡çš„å…¶ä»–è§£å†³æ–¹æ¡ˆã€‚

**ä¼˜å…ˆçº§**
- [ ] ä½
- [ ] ä¸­
- [ ] é«˜
- [ ] ç´§æ€¥
```

## ğŸ“š å­¦ä¹ èµ„æº

### ç›¸å…³æŠ€æœ¯æ–‡æ¡£
- [NVIDIA Jetsonå¼€å‘æŒ‡å—](https://developer.nvidia.com/jetson)
- [dustynvå®¹å™¨é¡¹ç›®](https://github.com/dusty-nv/jetson-containers)
- [FastAPIæ–‡æ¡£](https://fastapi.tiangolo.com/)
- [PyTorchæ–‡æ¡£](https://pytorch.org/docs/)

### é‡‘èAIç›¸å…³
- [Qwenæ¨¡å‹æ–‡æ¡£](https://github.com/QwenLM/Qwen)
- [PatchTSTè®ºæ–‡](https://arxiv.org/abs/2211.14730)
- [é‡‘èæƒ…æ„Ÿåˆ†ææœ€ä½³å®è·µ](https://huggingface.co/models?pipeline_tag=text-classification&search=financial)

## ğŸ† è´¡çŒ®è€…è®¤å¯

### è´¡çŒ®ç±»å‹
æˆ‘ä»¬è®¤å¯ä»¥ä¸‹ç±»å‹çš„è´¡çŒ®ï¼š
- ğŸ’» **ä»£ç è´¡çŒ®**: æ–°åŠŸèƒ½ã€é”™è¯¯ä¿®å¤ã€æ€§èƒ½ä¼˜åŒ–
- ğŸ“– **æ–‡æ¡£è´¡çŒ®**: æ–‡æ¡£æ”¹è¿›ã€æ•™ç¨‹ç¼–å†™
- ğŸ› **æµ‹è¯•è´¡çŒ®**: æµ‹è¯•ç”¨ä¾‹ã€æ€§èƒ½åŸºå‡†
- ğŸ¨ **è®¾è®¡è´¡çŒ®**: UI/UXè®¾è®¡ã€æ¶æ„è®¾è®¡
- ğŸ’¡ **æƒ³æ³•è´¡çŒ®**: åŠŸèƒ½å»ºè®®ã€æ¶æ„å»ºè®®

### è´¡çŒ®è€…åˆ—è¡¨
æ„Ÿè°¢æ‰€æœ‰ä¸ºé¡¹ç›®åšå‡ºè´¡çŒ®çš„å¼€å‘è€…ï¼è´¡çŒ®è€…å°†åœ¨é¡¹ç›®READMEä¸­å¾—åˆ°è®¤å¯ã€‚

## ğŸ“ è”ç³»æ–¹å¼

### æŠ€æœ¯è®¨è®º
- **GitHub Discussions**: https://github.com/firetoss/investiq-platform/discussions
- **æŠ€æœ¯é—®é¢˜**: é€šè¿‡GitHub Issuesæäº¤

### ä»£ç å®¡æŸ¥
- æ‰€æœ‰PRéƒ½éœ€è¦è‡³å°‘ä¸€ä¸ªç»´æŠ¤è€…çš„å®¡æŸ¥
- é‡å¤§å˜æ›´éœ€è¦ä¸¤ä¸ªç»´æŠ¤è€…çš„å®¡æŸ¥
- è‡ªåŠ¨åŒ–æµ‹è¯•å¿…é¡»é€šè¿‡

## ğŸ”’ å®‰å…¨æ”¿ç­–

### å®‰å…¨æ¼æ´æŠ¥å‘Š
å¦‚æœå‘ç°å®‰å…¨æ¼æ´ï¼Œè¯·ï¼š
1. **ä¸è¦**åœ¨å…¬å¼€Issueä¸­æŠ¥å‘Š
2. å‘é€é‚®ä»¶åˆ°å®‰å…¨å›¢é˜Ÿ (å¦‚æœæœ‰)
3. ç­‰å¾…å®‰å…¨å›¢é˜Ÿçš„å“åº”å’Œä¿®å¤

### å®‰å…¨æœ€ä½³å®è·µ
- ä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç å¯†é’¥æˆ–å¯†ç 
- ä½¿ç”¨ç¯å¢ƒå˜é‡ç®¡ç†æ•æ„Ÿé…ç½®
- å®šæœŸæ›´æ–°ä¾èµ–åŒ…
- éµå¾ªæœ€å°æƒé™åŸåˆ™

## ğŸ“‹ å¼€å‘æ£€æŸ¥æ¸…å•

### æäº¤å‰æ£€æŸ¥
- [ ] ä»£ç é€šè¿‡æ‰€æœ‰æµ‹è¯•
- [ ] ä»£ç ç¬¦åˆæ ¼å¼è§„èŒƒ
- [ ] æ·»åŠ äº†å¿…è¦çš„æ–‡æ¡£
- [ ] æ›´æ–°äº†ç›¸å…³çš„APIæ–‡æ¡£
- [ ] æ€§èƒ½æµ‹è¯•é€šè¿‡ (å¦‚æœé€‚ç”¨)
- [ ] å®‰å…¨æ£€æŸ¥é€šè¿‡

### PRæ£€æŸ¥æ¸…å•
- [ ] PRæ ‡é¢˜æ¸…æ™°æè¿°å˜æ›´
- [ ] PRæè¿°åŒ…å«å˜æ›´åŸå› å’Œå½±å“
- [ ] é“¾æ¥äº†ç›¸å…³çš„Issue
- [ ] æ·»åŠ äº†é€‚å½“çš„æ ‡ç­¾
- [ ] è¯·æ±‚äº†åˆé€‚çš„å®¡æŸ¥è€…

---

**ğŸ™ å†æ¬¡æ„Ÿè°¢æ‚¨çš„è´¡çŒ®ï¼æ¯ä¸€ä¸ªè´¡çŒ®éƒ½è®©InvestIQ Platformå˜å¾—æ›´å¥½ã€‚**
